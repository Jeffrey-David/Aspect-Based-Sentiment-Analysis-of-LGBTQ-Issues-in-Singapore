{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aspect term list\n",
    "General = ['lgbt', 'lgbtq', 'lgbtq+', 'lgbtqia+', 'homosexuality' , 'homosexual', 'homo', 'sexual orientation', 'gender dysphoria', 'gender identity' ]\n",
    "Gay = ['gay', 'ah gua', 'ah qua'] \n",
    "Lesbian = ['lesbian', 'les', 'sapphic']\n",
    "Bisexual = ['bisexual']\n",
    "Transgender =['transgender', 'tranny', 'ladyboy', 'trans', 'sex reassignment'] \n",
    "Queer = ['queer', 'non-binary', 'non binary']\n",
    "Same_Sex_Marriage = ['same-sex couples', 'same-sex marriage', 'same sex marriage', 'same-sex partner', 'same sex', 'gay marriage']\n",
    "LGBTQ_rights = [ 'rights', 'ivf', 'adoption', 'housing']  \n",
    "LGBTQ_mental_wellbeing = ['depression', 'suicide', 'mental health', 'mental illness']\n",
    "Diseases = ['hiv', 'hpv', 'syphilis', 'gonorrhoea', 'aids', 'diseases']\n",
    "Pride_Month = ['pink dot', 'wear white', 'pride month', 'pride parades']\n",
    "Anti_LGBTQ_Law = ['Anti-LGBTQ law', 'anti-LGBT laws', 'anti-LGBTQ laws', 's377a', 'Section377a', 'section 377A', '377a', 'anti-gay law', \n",
    "                'Anti LGBTQ law', 'anti LGBT laws', 'anti LGBTQ laws', 'anti gay law', '377a penal code']\n",
    "                \n",
    "\n",
    "\n",
    "ASPECT_TERM_LIST = []\n",
    "ASPECT_TERM_LIST.extend(General)\n",
    "ASPECT_TERM_LIST.extend(Gay)\n",
    "ASPECT_TERM_LIST.extend(Lesbian)\n",
    "ASPECT_TERM_LIST.extend(Bisexual)\n",
    "ASPECT_TERM_LIST.extend(Transgender)\n",
    "ASPECT_TERM_LIST.extend(Queer)\n",
    "ASPECT_TERM_LIST.extend(Same_Sex_Marriage)\n",
    "ASPECT_TERM_LIST.extend(LGBTQ_rights)\n",
    "ASPECT_TERM_LIST.extend(LGBTQ_mental_wellbeing)\n",
    "ASPECT_TERM_LIST.extend(Diseases)\n",
    "ASPECT_TERM_LIST.extend(Pride_Month)\n",
    "ASPECT_TERM_LIST.extend(Anti_LGBTQ_Law)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35666, 4)\n",
      "(35593, 4)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Load input CSV file\n",
    "#input_csv_path = \"filtered_comment_lgbtq.csv\"  # Update with your file path\n",
    "input_csv_path = \"fuzzy_filtered_data_processed.csv\"\n",
    "input_data = pd.read_csv(input_csv_path)\n",
    "print(input_data.shape)\n",
    "input_data.drop_duplicates(subset='comment', inplace=True)\n",
    "input_data.dropna(inplace=True)\n",
    "print(input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create lists to hold new data\n",
    "new_data = []\n",
    "\n",
    "# Regular expression pattern to split sentences\n",
    "sentence_split_pattern = r'(?<=[.?!])\\s+'\n",
    "\n",
    "# Initialize variable to store the previous sentence\n",
    "\n",
    "\n",
    "# Iterate through each comment\n",
    "for index, row in input_data.iterrows():\n",
    "    comment = row['comment']\n",
    "    sentences = re.split(sentence_split_pattern, comment)  # Split comment into sentences using regex\n",
    "    prev_sentence = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Check if the sentence is shorter than 6 words or longer than 50 words\n",
    "\n",
    "        this_sent = sentence\n",
    "        l_sentence = sentence.lower()\n",
    "\n",
    "        # Check if any aspect term is in the sentence as a single word\n",
    "        for aspect_term in ASPECT_TERM_LIST:\n",
    "            if len(sentence.split()) < 8:\n",
    "                sentence =  prev_sentence + \" \" + sentence \n",
    "            if re.search(r'\\b{}\\b'.format(aspect_term), l_sentence):\n",
    "                new_row = {\n",
    "                    'comment': sentence,\n",
    "                    'original_comment' : comment,\n",
    "                    'create_utc': row['create_utc'],\n",
    "                    'community': row['community'],\n",
    "                    #'score': row['score'],\n",
    "                    'aspect_term': aspect_term\n",
    "                }\n",
    "                new_data.append(new_row)\n",
    "                prev_sentence = this_sent\n",
    "\n",
    "# Create a new DataFrame\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "new_df.drop_duplicates(subset='comment', inplace=True)\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "output_csv_path = \"output.csv\"  \n",
    "new_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"CSV file created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
